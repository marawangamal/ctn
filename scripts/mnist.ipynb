{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4945c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, certifi\n",
    "from mtp.mheads._abc import AbstractDisributionHeadConfig\n",
    "from mtp.mheads import MHEADS\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fdfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Make the image binary: threshold at 0.5 after ToTensor, then convert to long (int)\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: (x > 0.5).long()])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "validation_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "# Report split sizes\n",
    "print(\"Training set has {} instances\".format(len(training_set)))\n",
    "print(\"Validation set has {} instances\".format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5747d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x150 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the first batch from the training loader\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show up to the first 10 images in the batch using seaborn\n",
    "num_images = min(10, images.shape[0])\n",
    "plt.figure(figsize=(num_images * 1.2, 1.5))  # Make images smaller\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    img = images[i].squeeze().numpy()\n",
    "    sns.heatmap(img, cmap='gray', cbar=False, xticklabels=False, yticklabels=False, square=True)\n",
    "    plt.title(f\"{labels[i].item()}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"First Batch Images (Labels shown above)\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b5571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 110/15000 [01:14<2:48:23,  1.47it/s, loss=0.713]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m output \u001b[38;5;241m=\u001b[39m model(z, y\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 33\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/github/mtl/.venv/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/mtl/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/mtl/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "num_epochs = 5\n",
    "lr = 0.001  \n",
    "\n",
    "model = MHEADS[\"moe_proj\"](\n",
    "    AbstractDisributionHeadConfig(\n",
    "        horizon=784,\n",
    "        d_model=10,  # 9 digits\n",
    "        d_output=2,  # 2 classes\n",
    "        rank=32,\n",
    "        pos_func='abs',\n",
    "    )\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(training_loader)\n",
    "    for batch in pbar:\n",
    "        y, x = batch  # for gen modelling reverse x, y\n",
    "        B = x.shape[0]\n",
    "        z = (\n",
    "            torch.nn.functional.one_hot(\n",
    "                x,\n",
    "                num_classes=10,\n",
    "            )\n",
    "            .reshape(B, -1)\n",
    "            .to(torch.float32)\n",
    "        )  # (B, 10)\n",
    "        z, y = z.to(device), y.to(device)\n",
    "        output = model(z, y.reshape(B, -1))\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item()}\")\n",
    "\n",
    "    # Sample\n",
    "    model.eval()\n",
    "    z = torch.nn.functional.one_hot(torch.tensor([0]), num_classes=10).to(torch.float32).to(device)\n",
    "    y = model.generate(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.nn.functional.one_hot(torch.tensor([0]), num_classes=10).to(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d53c5c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MHEADS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoe_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m](\n\u001b[1;32m      3\u001b[0m     AbstractDisributionHeadConfig(\n\u001b[1;32m      4\u001b[0m         horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m]), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/mtl/mtp/mheads/moe_proj.py:151\u001b[0m, in \u001b[0;36mMoEProjector.generate\u001b[0;34m(self, x, do_sample)\u001b[0m\n\u001b[1;32m    149\u001b[0m prob_y_bar_xy \u001b[38;5;241m=\u001b[39m prob_y_bar_xy \u001b[38;5;241m/\u001b[39m prob_y_bar_xy\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_sample:\n\u001b[0;32m--> 151\u001b[0m     y_out[:, h] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_y_bar_xy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     y_out[:, h] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(prob_y_bar_xy, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "model = MHEADS[\"moe_proj\"](\n",
    "    AbstractDisributionHeadConfig(\n",
    "        horizon=300,\n",
    "        d_model=10,  # 9 digits\n",
    "        d_output=2,  # 2 classes\n",
    "        rank=1,\n",
    "    )\n",
    ")\n",
    "z = torch.nn.functional.one_hot(torch.tensor([0]), num_classes=10).to(torch.float32).to(device)\n",
    "y = model.generate(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f614261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "         1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "         1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "         0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "         0, 1, 1, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c4a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
