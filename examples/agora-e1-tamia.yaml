# Experiment 1
# Evaluating efficacy of multi-token regularization
preambles:
  glong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --gres=gpu:4"
    - "#SBATCH --mem=32G"
    - "#SBATCH --cpus-per-task=8"
    - "source /scratch/m/mgamal/mtl/.venv/bin/activate"

group:
  name: "main"
  type: parallel
  jobs:

    - group:
        name: "stp::cosine"
        type: sequential
        jobs:
          - job:
              preamble: glong
              command: "HF_HOME=$SCRATCH/huggingface python train.py --model_head stp --lr 4e-3 --scheduler cosine --dataset fineweb::dt"

